import os
import cv2
import numpy as np
from PIL import Image
import torch
from lama_cleaner.model import LaMaInpainting
from realesrgan import RealESRGAN
from paddleocr import PaddleOCR
import gradio as gr

# =========================
# ๐ง Device Setup
# =========================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"๐ฅ๏ธ Using device: {device}")

# =========================
# Load Inpainting Model (Static)
# =========================
# This model is loaded only once because it does not depend on user settings
lama_model = LaMaInpainting(model_type='lama', device=device)
print("โ Text removal model loaded")

# Cache for models that depend on user settings
model_cache = {}

def get_ocr_model(lang):
    """Load or return OCR model from cache"""
    if lang not in model_cache:
        print(f"๐ Loading OCR model for language: {lang}")
        model_cache[lang] = PaddleOCR(use_angle_cls=True, lang=lang)
    return model_cache[lang]

def get_realesrgan_model(scale):
    """Load or return super-resolution model from cache"""
    key = f"realesrgan_x{scale}"
    if key not in model_cache:
        print(f"๐ Loading super-resolution model with scale: {scale}x")
        model = RealESRGAN(device, scale=scale)
        # Weights file depends on scale
        model.load_weights(f'RealESRGAN_x{scale}plus.pth', download=True)
        model_cache[key] = model
    return model_cache[key]

# =========================
# Single Page Processing Function
# =========================
def clean_page(image, ocr_model, lama_model, realesrgan_model):
    """Clean a single page: detect text, remove it, then enhance quality"""
    image_np = np.array(image.convert('RGB'))
    h, w = image_np.shape[:2]

    # 1. Text detection
    result = ocr_model.ocr(image_np)
    
    # 2. Create text mask
    mask = np.zeros((h, w), dtype=np.uint8)
    if result and result[0]:
        for line in result[0]:
            pts = np.array(line[0], dtype=np.int32)
            cv2.fillPoly(mask, [pts], 255)

    # 3. Remove text
    cleaned_image = lama_model(image_np, mask)

    # 4. Enhance quality
    upscaled_image = realesrgan_model.predict(cleaned_image)

    return Image.fromarray(upscaled_image)

# =========================
# Full Chapter Processing Function
# =========================
def clean_chapter_folder(chapter_folder, ocr_model, lama_model, realesrgan_model, output_format):
    """Process all images in a single chapter folder"""
    output_folder = os.path.join(chapter_folder, "chapter_cleaned")
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Supported image formats
    supported_formats = ('.png', '.jpg', '.jpeg', '.webp', '.tiff', '.bmp')
    files = sorted([f for f in os.listdir(chapter_folder) if f.lower().endswith(supported_formats)])
    
    if not files:
        print(f"โ๏ธ No images found in folder: {chapter_folder}")
        return None

    for idx, file in enumerate(files, 1):
        input_path = os.path.join(chapter_folder, file)
        print(f"๐ Processing page {idx}/{len(files)}: {file}")
        
        try:
            image = Image.open(input_path)
            result_image = clean_page(image, ocr_model, lama_model, realesrgan_model)
            
            # Save in the desired format
            file_name, _ = os.path.splitext(file)
            output_filename = f"{file_name}.{output_format.lower()}"
            output_path = os.path.join(output_folder, output_filename)

            if output_format == 'JPG':
                result_image.convert('RGB').save(output_path, 'jpeg', quality=95)
            else:
                result_image.save(output_path, output_format.upper())

        except Exception as e:
            print(f"โ Error processing file {file}: {e}")

    return output_folder

# =========================
# Main Function for Gradio
# =========================
def process_all_chapters(uploaded_files, lang, scale, output_format, progress=gr.Progress(track_tqdm=True)):
    """Function connecting UI with backend logic"""
    if not uploaded_files:
        return "Please select image files first."

    # Load models based on user selection
    progress(0, desc="Loading models...")
    ocr_model = get_ocr_model(lang)
    realesrgan_model = get_realesrgan_model(scale)

    # Infer root folder from uploaded files
    all_paths = [f.name for f in uploaded_files]
    root_path = os.path.commonpath(all_paths) if len(all_paths) > 1 else os.path.dirname(all_paths[0])

    # Search for chapter folders
    potential_chapters = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]

    chapters_to_process = []
    if potential_chapters:
        # Case 1: Subfolders (chapters) found
        chapters_to_process = [os.path.join(root_path, d) for d in potential_chapters]
        print(f"๐ Found {len(chapters_to_process)} chapters in: {root_path}")
    else:
        # Case 2: No subfolders, assume root folder is a single chapter
        chapters_to_process = [root_path]
        print(f"๐ No chapters found, processing current folder: {root_path}")

    if not chapters_to_process:
         return "No images found for processing in the selected folder."

    processed_chapters_summary = []
    for chapter_path in progress.tqdm(chapters_to_process, desc="Processing chapters"):
        chapter_name = os.path.basename(chapter_path)
        print(f"๐ Processing chapter: {chapter_name}")
        output_folder = clean_chapter_folder(chapter_path, ocr_model, lama_model, realesrgan_model, output_format)
        if output_folder:
            processed_chapters_summary.append(f"โ {chapter_name} -> {output_folder}")
        else:
            processed_chapters_summary.append(f"โ๏ธ {chapter_name} -> No images to process")

    return "\n".join(processed_chapters_summary)

# =========================
# Gradio Interface
# =========================
interface = gr.Interface(
    fn=process_all_chapters,
    inputs=[
        gr.Files(label="Select chapter images or drag the entire folder"),
        gr.Dropdown(['en', 'ar', 'ja', 'ko', 'ch_sim', 'fr', 'de'], label="Text language in images", value='en', info="Choose the language for accurate removal"),
        gr.Dropdown([2, 4], label="Super-resolution scale", value=2, info="2x is faster, 4x gives higher quality"),
        gr.Radio(['PNG', 'JPG'], label="Save cleaned images format", value='PNG')
    ],
    outputs=gr.Textbox(label="Status and results", lines=10),
    title="๐๏ธ Advanced Smart Manhwa Cleaner",
    description="Upload the images you want to clean. You can upload a single chapter or drag a folder containing multiple chapter folders.",
    allow_flagging='never',
    theme=gr.themes.Soft()
)

if __name__ == "__main__":
    # Note: On first run, models will be loaded and cached. This may take some time.
    # For RealESRGAN scale 4, make sure you have 'RealESRGAN_x4plus.pth' file available or let it download.
    interface.launch()
    if key not in model_cache:
        print(f"๐ ุชุญููู ูููุฐุฌ ุชุญุณูู ุงูุฌูุฏุฉ ุจูููุงุณ: {scale}x")
        model = RealESRGAN(device, scale=scale)
        # ุงุณู ููู ุงูุฃูุฒุงู ูุนุชูุฏ ุนูู ุงููููุงุณ
        model.load_weights(f'RealESRGAN_x{scale}plus.pth', download=True)
        model_cache[key] = model
    return model_cache[key]

# =========================
# ุฏุงูุฉ ูุนุงูุฌุฉ ุตูุญุฉ ูุงุญุฏุฉ
# =========================
def clean_page(image, ocr_model, lama_model, realesrgan_model):
    """ุชูุธูู ุตูุญุฉ ูุงุญุฏุฉ: ูุดู ุงููุตุ ุฅุฒุงูุชูุ ุซู ุชุญุณูู ุงูุฌูุฏุฉ"""
    image_np = np.array(image.convert('RGB'))
    h, w = image_np.shape[:2]

    # 1. ูุดู ุงููุตูุต
    result = ocr_model.ocr(image_np)
    
    # 2. ุฅูุดุงุก ููุงุน ูููุตูุต
    mask = np.zeros((h, w), dtype=np.uint8)
    if result and result[0]:
        for line in result[0]:
            pts = np.array(line[0], dtype=np.int32)
            cv2.fillPoly(mask, [pts], 255)

    # 3. ุฅุฒุงูุฉ ุงููุตูุต
    cleaned_image = lama_model(image_np, mask)

    # 4. ุชุญุณูู ุงูุฌูุฏุฉ
    upscaled_image = realesrgan_model.predict(cleaned_image)

    return Image.fromarray(upscaled_image)

# =========================
# ุฏุงูุฉ ูุนุงูุฌุฉ ูุตู ูุงูู
# =========================
def clean_chapter_folder(chapter_folder, ocr_model, lama_model, realesrgan_model, output_format):
    """ูุนุงูุฌุฉ ูู ุงูุตูุฑ ูู ูุฌูุฏ ูุตู ูุงุญุฏ"""
    output_folder = os.path.join(chapter_folder, "chapter_cleaned")
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # ุฏุนู ุตูุบ ุฅุถุงููุฉ
    supported_formats = ('.png', '.jpg', '.jpeg', '.webp', '.tiff', '.bmp')
    files = sorted([f for f in os.listdir(chapter_folder) if f.lower().endswith(supported_formats)])
    
    if not files:
        print(f"โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู ุตูุฑ ูู ุงููุฌูุฏ: {chapter_folder}")
        return None

    for idx, file in enumerate(files, 1):
        input_path = os.path.join(chapter_folder, file)
        print(f"๐ ูุนุงูุฌุฉ ุงูุตูุญุฉ {idx}/{len(files)}: {file}")
        
        try:
            image = Image.open(input_path)
            result_image = clean_page(image, ocr_model, lama_model, realesrgan_model)
            
            # ุญูุธ ุจุงูุตูุบุฉ ุงููุทููุจุฉ
            file_name, _ = os.path.splitext(file)
            output_filename = f"{file_name}.{output_format.lower()}"
            output_path = os.path.join(output_folder, output_filename)

            if output_format == 'JPG':
                result_image.convert('RGB').save(output_path, 'jpeg', quality=95)
            else:
                result_image.save(output_path, output_format.upper())

        except Exception as e:
            print(f"โ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ูุนุงูุฌุฉ ุงูููู {file}: {e}")

    return output_folder

# =========================
# ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ููุงุฌูุฉ Gradio
# =========================
def process_all_chapters(uploaded_files, lang, scale, output_format, progress=gr.Progress(track_tqdm=True)):
    """ุงูุฏุงูุฉ ุงูุชู ุชุฑุจุท ุงููุงุฌูุฉ ุจุงูููุทู ุงูุจุฑูุฌู"""
    if not uploaded_files:
        return "ูุฑุฌู ุงุฎุชูุงุฑ ูููุงุช ุงูุตูุฑ ุฃููุงู."

    # ุชุญููู ุงูููุงุฐุฌ ุจูุงุกู ุนูู ุงุฎุชูุงุฑ ุงููุณุชุฎุฏู
    progress(0, desc="ุชุญููู ุงูููุงุฐุฌ...")
    ocr_model = get_ocr_model(lang)
    realesrgan_model = get_realesrgan_model(scale)

    # ุงุณุชูุชุงุฌ ุงููุฌูุฏ ุงูุฌุฐุฑ ูู ูุงุฆูุฉ ุงููููุงุช
    all_paths = [f.name for f in uploaded_files]
    root_path = os.path.commonpath(all_paths) if len(all_paths) > 1 else os.path.dirname(all_paths[0])

    # ุงูุจุญุซ ุนู ูุฌูุฏุงุช ุงููุตูู
    potential_chapters = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]

    chapters_to_process = []
    if potential_chapters:
        # ุงูุญุงูุฉ 1: ุชู ุงูุนุซูุฑ ุนูู ูุฌูุฏุงุช ูุฑุนูุฉ (ูุตูู)
        chapters_to_process = [os.path.join(root_path, d) for d in potential_chapters]
        print(f"๐ ุชู ุงูุนุซูุฑ ุนูู {len(chapters_to_process)} ูุตูู ูู: {root_path}")
    else:
        # ุงูุญุงูุฉ 2: ูู ูุชู ุงูุนุซูุฑ ุนูู ูุฌูุฏุงุช ูุฑุนูุฉุ ุงูุชุฑุถ ุฃู ุงููุฌูุฏ ุงูุฌุฐุฑ ูู ุงููุตู ููุณู
        chapters_to_process = [root_path]
        print(f"๐ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุตููุ ุณูุชู ูุนุงูุฌุฉ ุงููุฌูุฏ ุงูุญุงูู: {root_path}")

    if not chapters_to_process:
         return "ูู ูุชู ุงูุนุซูุฑ ุนูู ุตูุฑ ูููุนุงูุฌุฉ ูู ุงููุฌูุฏ ุงููุญุฏุฏ."

    processed_chapters_summary = []
    for chapter_path in progress.tqdm(chapters_to_process, desc="ูุนุงูุฌุฉ ุงููุตูู"):
        chapter_name = os.path.basename(chapter_path)
        print(f"๐ ูุนุงูุฌุฉ ุงููุตู: {chapter_name}")
        output_folder = clean_chapter_folder(chapter_path, ocr_model, lama_model, realesrgan_model, output_format)
        if output_folder:
            processed_chapters_summary.append(f"โ {chapter_name} -> {output_folder}")
        else:
            processed_chapters_summary.append(f"โ๏ธ {chapter_name} -> ูุง ุชูุฌุฏ ุตูุฑ ูููุนุงูุฌุฉ")

    return "\n".join(processed_chapters_summary)

# =========================
# ูุงุฌูุฉ Gradio
# =========================
interface = gr.Interface(
    fn=process_all_chapters,
    inputs=[
        gr.Files(label="ุงุฎุชุฑ ุตูุฑ ุงููุตูู ุฃู ุงุณุญุจ ุงููุฌูุฏ ุจุฃูููู"),
        gr.Dropdown(['en', 'ar', 'ja', 'ko', 'ch_sim', 'fr', 'de'], label="ูุบุฉ ุงููุต ูู ุงูุตูุฑ", value='en', info="ุงุฎุชุฑ ุงููุบุฉ ูุฅุฒุงูุชูุง ุจุฏูุฉ"),
        gr.Dropdown([2, 4], label="ูููุงุณ ุชุญุณูู ุงูุฌูุฏุฉ", value=2, info="2x ูู ุงูุฃุณุฑุนุ 4x ูุนุทู ุฌูุฏุฉ ุฃุนูู"),
        gr.Radio(['PNG', 'JPG'], label="ุตูุบุฉ ุญูุธ ุงูุตูุฑ ุงููุธููุฉ", value='PNG')
    ],
    outputs=gr.Textbox(label="ุงูุญุงูุฉ ูุงููุชุงุฆุฌ", lines=10),
    title="๐๏ธ ููุธู ุงููุงูููุง ุงูุฐูู ุงููุทูุฑ",
    description="ุงุฑูุน ุงูุตูุฑ ุงูุชู ุชุฑูุฏ ุชูุธูููุง. ููููู ุฑูุน ุตูุฑ ูุตู ูุงุญุฏุ ุฃู ุณุญุจ ูุฌูุฏ ูุญุชูู ุนูู ุนุฏุฉ ูุฌูุฏุงุช ูุตูู.",
    allow_flagging='never',
    theme=gr.themes.Soft()
)

if __name__ == "__main__":
    # ููุงุญุธุฉ: ุนูุฏ ุชุดุบูู ุงูุจุฑูุงูุฌ ูุฃูู ูุฑุฉุ ุณูุชู ุชุญููู ูุชุฎุฒูู ุงูููุงุฐุฌ. ูุฏ ูุณุชุบุฑู ูุฐุง ุจุนุถ ุงูููุช.
    # For RealESRGAN scale 4, make sure you have 'RealESRGAN_x4plus.pth' file available or let it download.
    interface.launch()
