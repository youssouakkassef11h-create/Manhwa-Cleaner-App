{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üñåÔ∏è Advanced Smart Manhwa Cleaner\n",
    "\n",
    "Welcome! This notebook allows you to automatically clean text from comic pages (manhwa/manga) and enhance their quality. \n",
    "\n",
    "**Instructions:**\n",
    "1. Run the first cell (Setup) to install all the necessary libraries.\n",
    "2. Run the second cell (Main Application Code) to define all the functions.\n",
    "3. Run the third cell (Launch the App!) to start the web interface. A public URL will be generated ‚Äì click on it to open the application in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Setup\n",
    "# =========================\n",
    "print('‚è≥ Installing dependencies... This may take a few minutes.')\n",
    "!pip install torch torchvision numpy opencv-python scikit-image Pillow huggingface-hub loguru realesrgan lama-cleaner paddlepaddle-gpu paddleocr gradio\n",
    "print('‚úÖ Dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. Main Application Code\n",
    "# =========================\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import zipfile\n",
    "import tempfile\n",
    "from lama_cleaner.model import LaMaInpainting\n",
    "from realesrgan import RealESRGAN\n",
    "from paddleocr import PaddleOCR\n",
    "import gradio as gr\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'üñ•Ô∏è Using device: {device}')\n",
    "\n",
    "lama_model = LaMaInpainting(model_type='lama', device=device)\n",
    "print('‚úÖ Text removal model loaded')\n",
    "\n",
    "model_cache = {}\n",
    "\n",
    "def get_ocr_model(lang):\n",
    "    if lang not in model_cache:\n",
    "        print(f'üîÑ Loading OCR model for language: {lang}')\n",
    "        model_cache[lang] = PaddleOCR(use_angle_cls=True, lang=lang)\n",
    "    return model_cache[lang]\n",
    "\n",
    "def get_realesrgan_model(scale):\n",
    "    key = f'realesrgan_x{scale}'\n",
    "    if key not in model_cache:\n",
    "        print(f'üîÑ Loading super-resolution model with scale: {scale}x')\n",
    "        model = RealESRGAN(device, scale=scale)\n",
    "        model.load_weights(f'RealESRGAN_x{scale}plus.pth', download=True)\n",
    "        model_cache[key] = model\n",
    "    return model_cache[key]\n",
    "\n",
    "def clean_page(image, ocr_model, lama_model, realesrgan_model):\n",
    "    image_np = np.array(image.convert('RGB'))\n",
    "    h, w = image_np.shape[:2]\n",
    "    result = ocr_model.ocr(image_np)\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    if result and result[0]:\n",
    "        for line in result[0]:\n",
    "            pts = np.array(line[0], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, [pts], 255)\n",
    "    cleaned_image = lama_model(image_np, mask)\n",
    "    upscaled_image = realesrgan_model.predict(cleaned_image)\n",
    "    return Image.fromarray(upscaled_image)\n",
    "\n",
    "def clean_chapter_folder(chapter_folder, ocr_model, lama_model, realesrgan_model, output_format):\n",
    "    output_folder = os.path.join(chapter_folder, 'chapter_cleaned')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.webp', '.tiff', '.bmp')\n",
    "    files = sorted([f for f in os.listdir(chapter_folder) if f.lower().endswith(supported_formats)])\n",
    "    if not files:\n",
    "        print(f'‚ö†Ô∏è No images found in folder: {chapter_folder}')\n",
    "        return None\n",
    "    for idx, file in enumerate(files, 1):\n",
    "        input_path = os.path.join(chapter_folder, file)\n",
    "        print(f'üìÑ Processing page {idx}/{len(files)}: {file}')\n",
    "        try:\n",
    "            image = Image.open(input_path)\n",
    "            result_image = clean_page(image, ocr_model, lama_model, realesrgan_model)\n",
    "            file_name, _ = os.path.splitext(file)\n",
    "            output_filename = f'{file_name}.{output_format.lower()}'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            if output_format == 'JPG':\n",
    "                result_image.convert('RGB').save(output_path, 'jpeg', quality=95)\n",
    "            else:\n",
    "                result_image.save(output_path, output_format.upper())\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error processing file {file}: {e}')\n",
    "    return output_folder\n",
    "\n",
    "def process_all_chapters(uploaded_files, lang, scale, output_format, progress=gr.Progress(track_tqdm=True)):\n",
    "    if not uploaded_files:\n",
    "        return None, 'Please select image files first.'\n",
    "    progress(0, desc='Loading models...')\n",
    "    ocr_model = get_ocr_model(lang)\n",
    "    realesrgan_model = get_realesrgan_model(scale)\n",
    "    all_paths = [f.name for f in uploaded_files]\n",
    "    root_path = os.path.commonpath(all_paths) if len(all_paths) > 1 else os.path.dirname(all_paths[0])\n",
    "    potential_chapters = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "    chapters_to_process = []\n",
    "    if potential_chapters:\n",
    "        chapters_to_process = [os.path.join(root_path, d) for d in potential_chapters]\n",
    "        print(f'üìÇ Found {len(chapters_to_process)} chapters in: {root_path}')\n",
    "    else:\n",
    "        chapters_to_process = [root_path]\n",
    "        print(f'üìÇ No chapters found, processing current folder: {root_path}')\n",
    "    if not chapters_to_process:\n",
    "        return None, 'No images found for processing in the selected folder.'\n",
    "    processed_folders = []\n",
    "    for chapter_path in progress.tqdm(chapters_to_process, desc='Processing chapters'):\n",
    "        output_folder = clean_chapter_folder(chapter_path, ocr_model, lama_model, realesrgan_model, output_format)\n",
    "        if output_folder:\n",
    "            processed_folders.append(output_folder)\n",
    "    if not processed_folders:\n",
    "        return None, 'No images were processed.'\n",
    "    zip_path = os.path.join(tempfile.gettempdir(), 'cleaned_chapters.zip')\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for folder in processed_folders:\n",
    "            for root, _, files in os.walk(folder):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, os.path.dirname(folder))\n",
    "                    zipf.write(file_path, arcname=arcname)\n",
    "    return zip_path, f'‚úÖ Processing complete. Your download is ready.'\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=process_all_chapters,\n",
    "    inputs=[\n",
    "        gr.Files(label='Select chapter images or drag the entire folder'),\n",
    "        gr.Dropdown(['en', 'ar', 'ja', 'ko', 'ch_sim', 'fr', 'de'], label='Text language in images', value='en', info='Choose the language for accurate removal'),\n",
    "        gr.Dropdown([2, 4], label='Super-resolution scale', value=2, info='2x is faster, 4x gives higher quality'),\n",
    "        gr.Radio(['PNG', 'JPG'], label='Save cleaned images format', value='PNG')\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.File(label='Download cleaned chapters (.zip)'),\n",
    "        gr.Textbox(label='Status', lines=5)\n",
    "    ],\n",
    "    title='üñåÔ∏è Advanced Smart Manhwa Cleaner',\n",
    "    description='Upload the images you want to clean. You can upload a single chapter or drag a folder containing multiple chapter folders.',\n",
    "    allow_flagging='never',\n",
    "    theme=gr.themes.Soft()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. Launch the App!\n",
    "# =========================\n",
    "interface.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
